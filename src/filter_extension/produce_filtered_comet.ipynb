{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "import itertools\n",
    "from classifier import *\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = \"model2024-02-08_19_53.pt\"\n",
    "pikle_file_paths = [\"comet_samsum_train_z_entire.pkl\",\"comet_samsum_test_z_entire.pkl\",\"./comet_samsum_validation_z_entire.pkl\"]\n",
    "\n",
    "lambda_value = 0  #lambda convex combination value. 1 means 100% our predicted similarity scores, 0 means 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(dim_input=9725, num_classes=25).to(device)\n",
    "model.load_state_dict(torch.load(model_load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_dict= \\\n",
    "{'xNeed': np.array([1,0,0,0,0], dtype=np.float32),\n",
    " 'xIntent': np.array([0,1,0,0,0], dtype=np.float32),\n",
    " 'HinderedBy': np.array([0,0,1,0,0], dtype=np.float32),\n",
    " 'xWant':  np.array([0,0,0,1,0], dtype=np.float32),\n",
    " 'xReason':  np.array([0,0,0,0,1], dtype=np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back_to_dict(df, selected_comets):\n",
    "    converted_df = {}\n",
    "    for i, row in df.iterrows():\n",
    "        if i%25 == selected_comets[int(np.floor(i/25))] and converted_df.get(str(row[\"sample_id\"])):\n",
    "            converted_df[str(row[\"sample_id\"])][str(row[\"sentence_id\"])] = \\\n",
    "                {\"sentence\":row[\"sentence\"], \"relation\":row[\"cs_type\"], \"out\":row[\"cs\"]}\n",
    "        elif i%25 == selected_comets[int(np.floor(i/25))]:  converted_df[str(row[\"sample_id\"])] = \\\n",
    "            {str(row[\"sentence_id\"]): {\"sentence\":row[\"sentence\"], \"relation\":row[\"cs_type\"], \"out\":row[\"cs\"]}}\n",
    "    return converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(converted_dfs_and_paths):\n",
    "    for converted_df, path in converted_dfs_and_paths:\n",
    "        with open(path, \"w\") as file:\n",
    "            file.write(json.dumps(converted_df, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pikle_file_path in pikle_file_paths:\n",
    "    df = pd.read_pickle(pikle_file_path)\n",
    "    df[\"cs_type_ohe\"] = df[\"cs_type\"].map(ohe_dict)\n",
    "    df[\"complete_target_X\"] = df[[\"cs_type_ohe\",\"cs_encoded\"]].apply(lambda row: np.append(row.iloc[0],row.iloc[1]), axis=1)\n",
    "    preprocessed = df[[\"sample_id\",\"sentence_id\", \"cs_type_ohe\",\"cs_encoded\", \"cos_similary_cs_summmary\", \"complete_target_X\", \"cos_similary_cs_sentence\", \"sentence\", \"cs_type\", \"cs\"]]\n",
    "    X = preprocessed.groupby(['sample_id','sentence_id']).agg(X=(\"complete_target_X\",lambda x: list(itertools.chain.from_iterable(x))),sentece_similarities=(\"cos_similary_cs_sentence\",lambda x: list(x)))\n",
    "    \n",
    "    selected_comets = []\n",
    "    with torch.no_grad():\n",
    "        for _, row in X.iterrows():\n",
    "            convex_combination = np.sum([np.multiply(row[\"sentece_similarities\"], (1-lambda_value)), np.multiply(np.array(model(torch.tensor(row[\"X\"]).to(device)).cpu()),lambda_value)], axis=0)\n",
    "            selected_comets.append(convex_combination.argmax())\n",
    "    \n",
    "    target_dict = convert_back_to_dict(preprocessed, selected_comets)\n",
    "    converted_dfs_and_paths = [(target_dict,\\\n",
    "                                f\"{pikle_file_path[:-4]}_lambda_{lambda_value}.json\")]\n",
    "    save_files(converted_dfs_and_paths)\n",
    "    del df\n",
    "    del X\n",
    "    del preprocessed\n",
    "    del target_dict\n",
    "    del selected_comets\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
